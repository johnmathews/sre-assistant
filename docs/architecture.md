# Architecture

## System Overview

The HomeLab SRE Assistant is a LangChain-based AI agent that connects to live infrastructure telemetry and a knowledge
base to answer operational questions about a Proxmox homelab with 80+ services.

## Data Flow

The agent uses two distinct data access patterns:

```
                    User Question
                         |
                    FastAPI /ask
                         |
                  LangChain Agent
                   (tool router)
                /    |    |    \
               /     |    |     \
  Live Metrics    Logs   RAG    Infrastructure
       |           |   Retrieval     |
       v           v      |         v
+-----------+ +------+    v    +-----------+
|Prometheus | | Loki | +-----+ |Proxmox VE |
| (metrics) | |(logs)| |Chroma| | (config)  |
+-----------+ +------+ |Vector| +-----------+
+-----------+           |Store | +-----------+
|  Grafana  |           +-----+ |    PBS    |
| (alerts)  |             |     | (backups) |
+-----------+          Runbooks +-----------+
                       Playbooks
```

### Live Tool Calls

Structured API queries executed in real-time. Used for questions about current system state.

- **Prometheus** (`prometheus_*` tools) — metrics: CPU, memory, disk, network, custom exporters
- **Grafana** (`grafana_*` tools) — alert states, alert rule definitions
- **Loki** (`loki_*` tools) — application logs, error search, change correlation timelines
- **Proxmox VE** (`proxmox_*` tools) — VM/container config, node status, tasks
- **PBS** (`pbs_*` tools) — backup storage, backup groups, backup tasks

### RAG Retrieval

Embedded documents retrieved by semantic similarity. Used for operational knowledge.

- **Runbooks** — troubleshooting procedures, architecture docs, service configs
- **Ansible playbooks** — infrastructure-as-code, role definitions

The LangChain agent decides which approach to use based on the question.

## Service Dependencies

```
HomeLab SRE Assistant
  |
  +-- OpenAI API (LLM inference)
  |
  +-- Prometheus (metrics, scraping pve_exporter, node_exporter, cadvisor, etc.)
  |
  +-- Grafana (alerting API, unified alerting)
  |
  +-- Loki (optional — log aggregation, collected by Alloy)
  |
  +-- Proxmox VE API (optional — VM/container management)
  |
  +-- Proxmox Backup Server API (optional — backup status)
  |
  +-- Chroma vector store (local, on-disk)
```

Required: OpenAI API, Prometheus, Grafana.
Optional: Loki, Proxmox VE, PBS (tools are conditionally registered based on config).
Local: Chroma vector store (rebuilt via `make ingest`).

## Request Lifecycle

See [code-flow.md](code-flow.md) for the detailed request lifecycle.

## Failure Handling

Every external dependency has explicit error handling:

- **ConnectError** — "Cannot connect to {service} at {url}"
- **TimeoutException** — "{service} request timed out after {n}s"
- **HTTPStatusError** — "{service} API error: HTTP {code} - {body}"

All tools set `handle_tool_error = True` so errors are returned to the LLM as text (not raised as exceptions), allowing
the agent to report failures gracefully to the user.

## Configuration

Settings are loaded from environment variables via `pydantic-settings`. The `Settings` class in `src/config.py` defines
all configuration with sensible defaults. Optional integrations (Loki, Proxmox VE, PBS) default to empty strings, which
disables their tools.

## Deployment Plan

### Target Environment

The agent will run as Docker containers on the Infra VM (`infra`, LXC on Proxmox), managed by the existing
[home-server](https://github.com/johnmathews/home-server) Ansible project. This keeps deployment consistent with every
other service in the homelab.

### Sensitive Data Strategy

This is a **public repository**. Runbooks contain real infrastructure details (IPs, hostnames, SSH usernames, service
topology) that the RAG agent needs for useful answers. The deployment strategy handles this tension:

1. **Repository runbooks** — contain real operational content (kept as-is for now; acceptable risk for RFC1918 addresses)
2. **Ansible templates** — at deploy time, Ansible can template runbooks from inventory variables if sanitization is
   needed later
3. **`.env` file** — generated by Ansible from `templates/env.j2` with vault-encrypted secrets, never committed
4. **`docker-compose.yml`** — templated by Ansible to inject correct image tags, volume mounts, and network config

### Container Architecture

A single Docker image (multi-stage build, `python:3.13-slim`) contains all three services. The
`docker-compose.yml` overrides the command per service:

```
docker-compose.yml
  |
  +-- sre-ingest (one-shot)
  |     CMD: python -m scripts.ingest_runbooks
  |     Volumes: chroma_data:/app/.chroma_db
  |     Runs first, exits when done
  |
  +-- sre-api (FastAPI backend)
  |     CMD: uvicorn src.api.main:app --host 0.0.0.0 --port 8000
  |     Port: 8000
  |     Volumes: chroma_data:/app/.chroma_db
  |     Starts after ingest completes successfully
  |
  +-- sre-ui (Streamlit frontend)
        CMD: streamlit run src/ui/app.py --server.port 8501 --server.address 0.0.0.0
        Port: 8501
        Env: API_URL=http://sre-api:8000
        Starts after api is healthy
```

### Docker Compose Setup

**Prerequisites:** Docker and Docker Compose installed. A `.env` file with API keys (see `.env.example`).

**Option A — Build from source:**

```bash
git clone https://github.com/johnmathews/sre-assistant.git
cd sre-assistant
cp .env.example .env
# Edit .env with real values
docker compose up -d
```

**Option B — Use the pre-built image from ghcr.io:**

Create a `docker-compose.yml` that references the published image:

```yaml
services:
  sre-ingest:
    image: ghcr.io/johnmathews/sre-assistant:latest
    command: ["python", "-m", "scripts.ingest_runbooks"]
    env_file: .env
    volumes:
      - chroma_data:/app/.chroma_db

  sre-api:
    image: ghcr.io/johnmathews/sre-assistant:latest
    ports:
      - "8000:8000"
    env_file: .env
    volumes:
      - chroma_data:/app/.chroma_db
    depends_on:
      sre-ingest:
        condition: service_completed_successfully

  sre-ui:
    image: ghcr.io/johnmathews/sre-assistant:latest
    command: ["streamlit", "run", "src/ui/app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://sre-api:8000
    depends_on:
      - sre-api

volumes:
  chroma_data:
```

Then create a `.env` file (see `.env.example` for required variables) and run `docker compose up -d`.

**Verify it's working:**

```bash
# Check all containers are running
docker compose ps

# Check API health
curl http://localhost:8000/health

# View logs
docker compose logs -f sre-api

# Open the web UI
open http://localhost:8501
```

**Re-ingest runbooks** (e.g. after updating runbook content):

```bash
docker compose run --rm sre-ingest
```

### Networking

- All containers share a Docker bridge network with access to Prometheus, Grafana, Proxmox VE, and PBS on the LAN
- No macOS local network permission issues (Linux host)
- Traefik reverse proxy provides HTTPS access via Cloudflare tunnel

### Secrets Management

All secrets are managed via Ansible Vault, consistent with the rest of the homelab:

| Secret | Source | Injected Via |
|--------|--------|-------------|
| `OPENAI_API_KEY` | Ansible Vault | `.env` template |
| `GRAFANA_SERVICE_ACCOUNT_TOKEN` | Ansible Vault | `.env` template |
| `PROXMOX_API_TOKEN` | Ansible Vault | `.env` template |
| `PBS_API_TOKEN` | Ansible Vault | `.env` template |

### RAG Document Sources

The vector store is built from multiple directories configured via `EXTRA_DOCS_DIRS`:

- `runbooks/` — bundled in this repo, operational procedures and architecture docs
- External documentation directories — referenced by absolute path on the host, mounted into the ingest container

The ingest process is strictly read-only — it reads `.md` files via `Path.read_text()` and writes only to the
`.chroma_db/` directory.
