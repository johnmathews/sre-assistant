# Architecture

## System Overview

The HomeLab SRE Assistant is a LangChain-based AI agent that connects to live infrastructure telemetry and a knowledge
base to answer operational questions about a Proxmox homelab with 80+ services.

## Data Flow

The agent uses two distinct data access patterns:

```
                    User Question
                         |
                    FastAPI /ask
                         |
                  LangChain Agent
                   (tool router)
                /    |    |    \
               /     |    |     \
  Live Metrics    Logs   RAG    Infrastructure
       |           |   Retrieval     |
       v           v      |         v
+-----------+ +------+    v    +-----------+
|Prometheus | | Loki | +-----+ |Proxmox VE |
| (metrics) | |(logs)| |Chroma| | (config)  |
+-----------+ +------+ |Vector| +-----------+
+-----------+           |Store | +-----------+
|  Grafana  |           +-----+ |    PBS    |
| (alerts)  |             |     | (backups) |
+-----------+          Runbooks +-----------+
                       Playbooks
```

### Live Tool Calls

Structured API queries executed in real-time. Used for questions about current system state.

- **Prometheus** (`prometheus_*` tools) — metrics: CPU, memory, disk, network, custom exporters
- **Grafana** (`grafana_*` tools) — alert states, alert rule definitions
- **Loki** (`loki_*` tools) — application logs, error search, change correlation timelines
- **Proxmox VE** (`proxmox_*` tools) — VM/container config, node status, tasks
- **PBS** (`pbs_*` tools) — backup storage, backup groups, backup tasks

### RAG Retrieval

Embedded documents retrieved by semantic similarity. Used for operational knowledge.

- **Runbooks** — troubleshooting procedures, architecture docs, service configs
- **Ansible playbooks** — infrastructure-as-code, role definitions

The LangChain agent decides which approach to use based on the question.

## Service Dependencies

```
HomeLab SRE Assistant
  |
  +-- OpenAI API (LLM inference)
  |
  +-- Prometheus (metrics, scraping pve_exporter, node_exporter, cadvisor, etc.)
  |
  +-- Grafana (alerting API, unified alerting)
  |
  +-- Loki (optional — log aggregation, collected by Alloy)
  |
  +-- Proxmox VE API (optional — VM/container management)
  |
  +-- Proxmox Backup Server API (optional — backup status)
  |
  +-- Chroma vector store (local, on-disk)
```

Required: OpenAI API, Prometheus, Grafana.
Optional: Loki, Proxmox VE, PBS (tools are conditionally registered based on config).
Local: Chroma vector store (rebuilt via `make ingest`).

## Request Lifecycle

See [code-flow.md](code-flow.md) for the detailed request lifecycle.

## Failure Handling

Every external dependency has explicit error handling:

- **ConnectError** — "Cannot connect to {service} at {url}"
- **TimeoutException** — "{service} request timed out after {n}s"
- **HTTPStatusError** — "{service} API error: HTTP {code} - {body}"

All tools set `handle_tool_error = True` so errors are returned to the LLM as text (not raised as exceptions), allowing
the agent to report failures gracefully to the user.

## Configuration

Settings are loaded from environment variables via `pydantic-settings`. The `Settings` class in `src/config.py` defines
all configuration with sensible defaults. Optional integrations (Loki, Proxmox VE, PBS) default to empty strings, which
disables their tools.

## Deployment Plan

### Target Environment

The agent will run as Docker containers on the Infra VM (`infra`, LXC on Proxmox), managed by the existing
[home-server](https://github.com/johnmathews/home-server) Ansible project. This keeps deployment consistent with every
other service in the homelab.

### Sensitive Data Strategy

This is a **public repository**. Runbooks contain real infrastructure details (IPs, hostnames, SSH usernames, service
topology) that the RAG agent needs for useful answers. The deployment strategy handles this tension:

1. **Repository runbooks** — contain real operational content (kept as-is for now; acceptable risk for RFC1918 addresses)
2. **Ansible templates** — at deploy time, Ansible can template runbooks from inventory variables if sanitization is
   needed later
3. **`.env` file** — generated by Ansible from `templates/env.j2` with vault-encrypted secrets, never committed
4. **`docker-compose.yml`** — templated by Ansible to inject correct image tags, volume mounts, and network config

### Container Architecture

```
docker-compose.yml (generated by Ansible)
  |
  +-- sre-api (FastAPI backend)
  |     Port: 8000
  |     Volumes: .env, .chroma_db/
  |
  +-- sre-ui (Streamlit frontend)
  |     Port: 8501
  |     Env: API_URL=http://sre-api:8000
  |
  +-- sre-ingest (one-shot)
        Rebuilds Chroma vector store
        Volumes: runbooks/, .chroma_db/
```

### Networking

- All containers share a Docker bridge network with access to Prometheus, Grafana, Proxmox VE, and PBS on the LAN
- No macOS local network permission issues (Linux host)
- Traefik reverse proxy provides HTTPS access via Cloudflare tunnel

### Secrets Management

All secrets are managed via Ansible Vault, consistent with the rest of the homelab:

| Secret | Source | Injected Via |
|--------|--------|-------------|
| `OPENAI_API_KEY` | Ansible Vault | `.env` template |
| `GRAFANA_SERVICE_ACCOUNT_TOKEN` | Ansible Vault | `.env` template |
| `PROXMOX_API_TOKEN` | Ansible Vault | `.env` template |
| `PBS_API_TOKEN` | Ansible Vault | `.env` template |

### RAG Document Sources

The vector store is built from multiple directories configured via `EXTRA_DOCS_DIRS`:

- `runbooks/` — bundled in this repo, operational procedures and architecture docs
- External documentation directories — referenced by absolute path on the host, mounted into the ingest container

The ingest process is strictly read-only — it reads `.md` files via `Path.read_text()` and writes only to the
`.chroma_db/` directory.
